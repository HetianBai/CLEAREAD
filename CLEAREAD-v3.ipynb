{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:47:28.901010Z",
     "start_time": "2020-06-29T02:47:23.924956Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from pattern.en import lemma\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import uuid\n",
    "import csv\n",
    "import phrasemachine\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request\n",
    "import difflib\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wechatpy.client import WeChatClient\n",
    "import random\n",
    "import http.client\n",
    "import stardict\n",
    "from stardict import LemmaDB\n",
    "lemma = LemmaDB()\n",
    "lemma.load('lemma.en.txt')\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:47:47.322710Z",
     "start_time": "2020-06-29T02:47:28.904003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\apps\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "GMAT_list = []\n",
    "\n",
    "with open('GMAT_edited.txt','r',encoding='utf-8') as fhandle:\n",
    "    for line in fhandle:\n",
    "        GMAT_list.append(line.lower().rstrip())\n",
    "    \n",
    "\n",
    "word_pron_char_defin_cate = []   \n",
    "df = pd.read_csv(\"stardict.csv\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:47:19.786500Z",
     "start_time": "2020-06-29T02:46:49.999797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the name of the v2fileHeartistheonlyhuntervocabularycounts_v2\n"
     ]
    }
   ],
   "source": [
    "filename = input('enter the name of the v2file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T02:55:51.939360Z",
     "start_time": "2020-06-29T02:47:48.778682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready for chinese translation\n"
     ]
    }
   ],
   "source": [
    "csvFile = open( filename + \".csv\", \"r\",encoding = 'utf-8')\n",
    "reader = csv.reader(csvFile)\n",
    "\n",
    "# API id and key\n",
    "app_id = '05d6c109'\n",
    "app_key = '63bda9528e24dff26ca5dd695b008acf'\n",
    "\n",
    "for i in reader:\n",
    "    try:\n",
    "        category = re.findall(\"[a-z]+\\-?[a-z]+\", df.loc[df['word']== i[0] ,'tag'].to_string())\n",
    "        if i[0] in GMAT_list:\n",
    "            category.append('gmat')\n",
    "        cate = \",\".join(category)\n",
    "    \n",
    "        try:\n",
    "    \n",
    "            word_id = i[0]\n",
    "            strictMatch = 'false'\n",
    "\n",
    "            url = 'https://od-api.oxforddictionaries.com:443/api/v2/entries/en-gb/' + word_id.lower() + '?strictMatch=' + strictMatch;\n",
    "\n",
    "            r = requests.get(url, headers = {'app_id': app_id, 'app_key': app_key})\n",
    "            pron = r.json()[\"results\"][0]['lexicalEntries'][0]['entries'][0]['pronunciations'][0]['phoneticSpelling']\n",
    "            char = r.json()[\"results\"][0]['lexicalEntries'][0]['lexicalCategory']['text']\n",
    "            defin = r.json()[\"results\"][0]['lexicalEntries'][0]['entries'][0]['senses'][0]['definitions'][0]\n",
    "            word_pron_char_defin_cate.append([i[0],'/'+pron+'/',char,defin,cate])\n",
    "            time.sleep(10)\n",
    "        except KeyError :\n",
    "            pass\n",
    "        continue\n",
    "    except IndexError:\n",
    "        pass\n",
    "print('ready for chinese translation')\n",
    "\n",
    "for i in word_pron_char_defin_cate:\n",
    "    if i[2] == 'Noun':\n",
    "        i[2] = 'n.'\n",
    "    if i[2] == 'Adjective':\n",
    "        i[2] = 'adj.'\n",
    "    if i[2] == 'Verb':\n",
    "        i[2] = 'v.'\n",
    "    if i[2] == 'Adverb':\n",
    "        i[2] = 'adv.'\n",
    "\n",
    "# Baidu API for EN-CN Translate\n",
    "appid = '20200627000507736'  # 填写你的appid\n",
    "secretKey = 'G3ghonyD9dfI39NnFtGN'  # 填写你的密钥\n",
    "\n",
    "httpClient = None\n",
    "myurl = '/api/trans/vip/translate'\n",
    "\n",
    "fromLang = 'en'   #原文语种\n",
    "toLang = 'zh'   #译文语种\n",
    "\n",
    "word_pron_char_defin_cate_cn = []\n",
    "for i in word_pron_char_defin_cate:\n",
    "    salt = random.randint(32768, 65536)\n",
    "    sign = appid + i[0] + str(salt) + secretKey\n",
    "    sign = hashlib.md5(sign.encode()).hexdigest()\n",
    "    myurl = myurl + '?appid=' + appid + '&q=' + urllib.parse.quote(i[0]) + '&from=' + fromLang + '&to=' + toLang + '&salt=' + str(salt) + '&sign=' + sign\n",
    "\n",
    "    try:\n",
    "        httpClient = http.client.HTTPConnection('api.fanyi.baidu.com')\n",
    "        httpClient.request('GET', myurl)\n",
    "\n",
    "        # response是HTTPResponse对象\n",
    "        response = httpClient.getresponse()\n",
    "        result_all = response.read().decode(\"utf-8\")\n",
    "        result = json.loads(result_all)['trans_result'][0]['dst']\n",
    "        i.append(result)\n",
    "        word_pron_char_defin_cate_cn.append(i)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "fileObject = open(filename + '_v3.txt', 'w',encoding='utf-8')\n",
    "for i in word_pron_char_defin_cate_cn:\n",
    "    for j in i:\n",
    "        fileObject.write(j)\n",
    "        fileObject.write(' ')\n",
    "    fileObject.write('\\n')\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

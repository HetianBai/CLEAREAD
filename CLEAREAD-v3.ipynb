{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T04:29:15.427361Z",
     "start_time": "2020-07-30T04:29:14.916726Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from pattern.en import lemma\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import uuid\n",
    "import csv\n",
    "import phrasemachine\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request\n",
    "import difflib\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wechatpy.client import WeChatClient\n",
    "import random\n",
    "import http.client\n",
    "import stardict\n",
    "from stardict import LemmaDB\n",
    "lemma = LemmaDB()\n",
    "lemma.load('lemma.en.txt')\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T04:29:15.554022Z",
     "start_time": "2020-07-30T04:29:15.549038Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"master_word_list.json\",'r') as load_f:\n",
    "    master_word_dict = json.load(load_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T04:29:32.592592Z",
     "start_time": "2020-07-30T04:29:19.461705Z"
    }
   },
   "outputs": [],
   "source": [
    "GMAT_list = []\n",
    "\n",
    "with open('GMAT_edited.txt','r',encoding='utf-8') as fhandle:\n",
    "    for line in fhandle:\n",
    "        GMAT_list.append(line.lower().rstrip())\n",
    "    \n",
    "\n",
    "word_pron_char_defin_cate = []   \n",
    "df = pd.read_csv(\"stardict.csv\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T04:29:46.923371Z",
     "start_time": "2020-07-30T04:29:32.598575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the name of the v2fileSomething I've Been Meaning to - Alice Munrovocabularycounts_v2\n"
     ]
    }
   ],
   "source": [
    "filename = input('enter the name of the v2file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T04:42:45.430691Z",
     "start_time": "2020-07-30T04:30:01.607563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mock\n",
      "couch\n",
      "spite\n",
      "pier\n",
      "dine\n",
      "cemetery\n",
      "fairground\n",
      "grab\n",
      "vomit\n",
      "stave\n",
      "gin\n",
      "flap\n",
      "outfit\n",
      "embroider\n",
      "wade\n",
      "presumable\n",
      "meditate\n",
      "closet\n",
      "peanut\n",
      "spin-dry\n",
      "rip\n",
      "mow\n",
      "limestone\n",
      "fling\n",
      "shrub\n",
      "fraud\n",
      "tar\n",
      "haul\n",
      "eyelid\n",
      "bleach\n",
      "braid\n",
      "stroll\n",
      "doorway\n",
      "copyright\n",
      "satin\n",
      "commonplace\n",
      "humiliate\n",
      "sap\n",
      "discourse\n",
      "landscape\n",
      "wringer\n",
      "forgiveness\n",
      "literally\n",
      "asthma\n",
      "psychiatrist\n",
      "skinny\n",
      "relish\n",
      "quiver\n",
      "kidney\n",
      "filthy\n",
      "frail\n",
      "scornful\n",
      "wagon\n",
      "elm\n",
      "lumberjack\n",
      "cot\n",
      "mattress\n",
      "pneumonia\n",
      "disgrace\n",
      "ready for chinese translation\n"
     ]
    }
   ],
   "source": [
    "csvFile = open( filename + \".csv\", \"r\",encoding = 'utf-8')\n",
    "reader = csv.reader(csvFile)\n",
    "\n",
    "# API id and key\n",
    "app_id = '7306b1b6'\n",
    "app_key = '11013df45a50b3d7960bdcb4fe77af01'\n",
    "\n",
    "word_pron_char_cate=[]\n",
    "for i in reader:\n",
    "    try:\n",
    "        category = re.findall(\"[a-z]+\\-?[a-z]+\", df.loc[df['word']== i[0] ,'tag'].to_string())\n",
    "        if i[0] in GMAT_list:\n",
    "            category.append('gmat')\n",
    "        cate = \",\".join(category)\n",
    "    \n",
    "        try:\n",
    "    \n",
    "            word_id = i[0]\n",
    "            strictMatch = 'false'\n",
    "\n",
    "            url = 'https://od-api.oxforddictionaries.com:443/api/v2/entries/en-gb/' + word_id.lower() + '?strictMatch=' + strictMatch;\n",
    "\n",
    "            r = requests.get(url, headers = {'app_id': app_id, 'app_key': app_key})\n",
    "            pron = r.json()[\"results\"][0]['lexicalEntries'][0]['entries'][0]['pronunciations'][0]['phoneticSpelling']\n",
    "            char = r.json()[\"results\"][0]['lexicalEntries'][0]['lexicalCategory']['text']\n",
    "            word_pron_char_cate.append([i[0],'/'+pron+'/',char,cate])\n",
    "            print(word_id)\n",
    "            time.sleep(10)\n",
    "        except KeyError :\n",
    "            pass\n",
    "        continue\n",
    "    except IndexError:\n",
    "        pass\n",
    "print('ready for chinese translation')\n",
    "\n",
    "for i in word_pron_char_cate:\n",
    "    if i[2] == 'Noun':\n",
    "        i[2] = 'n.'\n",
    "    if i[2] == 'Adjective':\n",
    "        i[2] = 'adj.'\n",
    "    if i[2] == 'Verb':\n",
    "        i[2] = 'v.'\n",
    "    if i[2] == 'Adverb':\n",
    "        i[2] = 'adv.'\n",
    "    if i[2] == 'Preposition':\n",
    "        i[2] = 'prep.'       \n",
    "    if i[2] == 'Conjunction':\n",
    "        i[2] = 'conj.' \n",
    "\n",
    "# Baidu API for EN-CN Translate\n",
    "appid = '20200627000507736'  # 填写你的appid\n",
    "secretKey = 'G3ghonyD9dfI39NnFtGN'  # 填写你的密钥\n",
    "\n",
    "httpClient = None\n",
    "myurl = '/api/trans/vip/translate'\n",
    "\n",
    "fromLang = 'en'   #原文语种\n",
    "toLang = 'zh'   #译文语种\n",
    "\n",
    "word_pron_char_cate_cn = []\n",
    "for i in word_pron_char_cate:\n",
    "    salt = random.randint(32768, 65536)\n",
    "    sign = appid + i[0] + str(salt) + secretKey\n",
    "    sign = hashlib.md5(sign.encode()).hexdigest()\n",
    "    myurl = myurl + '?appid=' + appid + '&q=' + urllib.parse.quote(i[0]) + '&from=' + fromLang + '&to=' + toLang + '&salt=' + str(salt) + '&sign=' + sign\n",
    "\n",
    "    try:\n",
    "        httpClient = http.client.HTTPConnection('api.fanyi.baidu.com')\n",
    "        httpClient.request('GET', myurl)\n",
    "\n",
    "        # response是HTTPResponse对象\n",
    "        response = httpClient.getresponse()\n",
    "        result_all = response.read().decode(\"utf-8\")\n",
    "        result = json.loads(result_all)['trans_result'][0]['dst']\n",
    "        i.append(result)\n",
    "        print(result)\n",
    "        word_pron_char_cate_cn.append(i)\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "def get_key (dict, value):\n",
    "    return [k for k, v in dict.items() if v == value]\n",
    "for i in range(0,len(word_pron_char_cate_cn)):\n",
    "    for j in list(master_word_dict.values()):\n",
    "        if word_pron_char_cate_cn[i][0] in j:\n",
    "            word_pron_char_cate_cn[i].append('Replicate')\n",
    "        else:\n",
    "            pass    \n",
    "fileObject = open(filename + '_v3.txt', 'w',encoding='utf-8')\n",
    "for i in word_pron_char_cate_cn:\n",
    "    for j in i:\n",
    "        fileObject.write(j)\n",
    "        fileObject.write(' ')\n",
    "    fileObject.write('\\n')\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T04:53:00.703045Z",
     "start_time": "2020-07-30T04:52:34.358924Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "嘲弄\n",
      "沙发\n",
      "怨恨\n",
      "码头\n",
      "设宴款待\n",
      "墓地\n",
      "游乐场\n",
      "抓住\n",
      "呕吐物\n",
      "梯级\n",
      "杜松子酒\n",
      "拍打\n",
      "装备\n",
      "刺绣\n",
      "韦德\n",
      "可能的\n",
      "冥想\n",
      "衣柜\n",
      "花生\n",
      "旋干\n",
      "裂开\n",
      "修剪\n",
      "石灰石\n",
      "猛扔\n",
      "灌木\n",
      "欺诈\n",
      "焦油\n",
      "拖\n",
      "眼睑\n",
      "漂白剂\n",
      "编织物\n",
      "散步\n",
      "门道\n",
      "版权\n",
      "缎子\n",
      "常见的事\n",
      "羞辱\n",
      "活力\n",
      "话语\n",
      "景观\n",
      "扭动\n",
      "宽恕\n",
      "从字面上看\n",
      "哮喘\n",
      "精神病医生\n",
      "极瘦的\n",
      "津津有味\n",
      "颤抖\n",
      "肾\n",
      "肮脏的\n",
      "脆弱的\n",
      "轻蔑的\n",
      "马车\n",
      "榆树\n",
      "伐木工人\n",
      "童床\n",
      "床垫\n",
      "肺炎\n",
      "耻辱\n"
     ]
    }
   ],
   "source": [
    "# Baidu API for EN-CN Translate\n",
    "appid = '20200627000507736'  # 填写你的appid\n",
    "secretKey = 'G3ghonyD9dfI39NnFtGN'  # 填写你的密钥\n",
    "\n",
    "httpClient = None\n",
    "myurl = '/api/trans/vip/translate'\n",
    "\n",
    "fromLang = 'en'   #原文语种\n",
    "toLang = 'zh'   #译文语种\n",
    "\n",
    "word_pron_char_cate_cn = []\n",
    "for i in word_pron_char_cate:\n",
    "    salt = random.randint(32768, 65536)\n",
    "    sign = appid + i[0] + str(salt) + secretKey\n",
    "    sign = hashlib.md5(sign.encode()).hexdigest()\n",
    "    myurl = myurl + '?appid=' + appid + '&q=' + urllib.parse.quote(i[0]) + '&from=' + fromLang + '&to=' + toLang + '&salt=' + str(salt) + '&sign=' + sign\n",
    "\n",
    "    try:\n",
    "        httpClient = http.client.HTTPConnection('api.fanyi.baidu.com')\n",
    "        httpClient.request('GET', myurl)\n",
    "\n",
    "        # response是HTTPResponse对象\n",
    "        response = httpClient.getresponse()\n",
    "        result_all = response.read().decode(\"utf-8\")\n",
    "        result = json.loads(result_all)['trans_result'][0]['dst']\n",
    "        i.append(result)\n",
    "        print(result)\n",
    "        word_pron_char_cate_cn.append(i)\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass\n",
    "    \n",
    "def get_key (dict, value):\n",
    "    return [k for k, v in dict.items() if v == value]\n",
    "for i in range(0,len(word_pron_char_cate_cn)):\n",
    "    for j in list(master_word_dict.values()):\n",
    "        if word_pron_char_cate_cn[i][0] in j:\n",
    "            word_pron_char_cate_cn[i].append('Replicate')\n",
    "        else:\n",
    "            pass    \n",
    "fileObject = open(filename + '_v3.txt', 'w',encoding='utf-8')\n",
    "for i in word_pron_char_cate_cn:\n",
    "    for j in i:\n",
    "        fileObject.write(j)\n",
    "        fileObject.write(' ')\n",
    "    fileObject.write('\\n')\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

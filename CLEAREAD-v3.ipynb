{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:51:16.050211Z",
     "start_time": "2020-07-15T04:51:14.380673Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from pattern.en import lemma\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import hashlib\n",
    "import uuid\n",
    "import csv\n",
    "import phrasemachine\n",
    "import time\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request\n",
    "import difflib\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wechatpy.client import WeChatClient\n",
    "import random\n",
    "import http.client\n",
    "import stardict\n",
    "from stardict import LemmaDB\n",
    "lemma = LemmaDB()\n",
    "lemma.load('lemma.en.txt')\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T04:51:47.923013Z",
     "start_time": "2020-07-15T04:51:18.308178Z"
    }
   },
   "outputs": [],
   "source": [
    "GMAT_list = []\n",
    "\n",
    "with open('GMAT_edited.txt','r',encoding='utf-8') as fhandle:\n",
    "    for line in fhandle:\n",
    "        GMAT_list.append(line.lower().rstrip())\n",
    "    \n",
    "\n",
    "word_pron_char_defin_cate = []   \n",
    "df = pd.read_csv(\"stardict.csv\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T04:06:34.705671Z",
     "start_time": "2020-07-17T04:06:33.038151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the name of the v2fileAnimal Farmvocabularycounts_v2\n"
     ]
    }
   ],
   "source": [
    "filename = input('enter the name of the v2file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T04:18:15.916879Z",
     "start_time": "2020-07-17T04:06:36.001520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "windmill\n",
      "clover\n",
      "hoof\n",
      "stall\n",
      "ration\n",
      "cowshed\n",
      "pasture\n",
      "orchard\n",
      "fling\n",
      "spite\n",
      "bleat\n",
      "trotter\n",
      "expulsion\n",
      "quarry\n",
      "pellet\n",
      "growl\n",
      "cockerel\n",
      "barley\n",
      "gallop\n",
      "fro\n",
      "wound\n",
      "perch\n",
      "whisk\n",
      "snuff\n",
      "thou\n",
      "hind\n",
      "onward\n",
      "toil\n",
      "maxim\n",
      "boar\n",
      "knoll\n",
      "machinery\n",
      "skull\n",
      "boulder\n",
      "decree\n",
      "procure\n",
      "oat\n",
      "flagstaff\n",
      "mane\n",
      "dynamo\n",
      "overthrow\n",
      "mare\n",
      "simultaneously\n",
      "uproar\n",
      "thresh\n",
      "inscribe\n",
      "raven\n",
      "lash\n",
      "hayfield\n",
      "duckling\n",
      "flutter\n",
      "tread\n",
      "knacker\n",
      "shrill\n",
      "hoist\n",
      "mash\n",
      "suppress\n",
      "ready for chinese translation\n",
      "风车\n",
      "三叶草\n",
      "蹄\n",
      "失速\n",
      "定额\n",
      "牛棚\n",
      "牧场\n",
      "果园\n",
      "猛扔\n",
      "怨恨\n",
      "惨叫\n",
      "小跑\n",
      "驱逐\n",
      "采石场\n",
      "弹丸\n",
      "咆哮\n",
      "公鸡\n",
      "大麦\n",
      "驰骋\n",
      "从\n",
      "伤口\n",
      "鲈鱼\n",
      "搅拌\n",
      "鼻烟\n",
      "你\n",
      "后面的\n",
      "向前的\n",
      "辛苦工作\n",
      "格言\n",
      "野猪\n",
      "小丘\n",
      "机械\n",
      "颅骨\n",
      "巨石\n",
      "法令\n",
      "采购\n",
      "燕麦\n",
      "旗杆\n",
      "鬃毛\n",
      "发电机\n",
      "推翻\n",
      "母马\n",
      "同时\n",
      "喧嚣\n",
      "脱粒\n",
      "题词\n",
      "掠夺\n",
      "睫毛\n",
      "海菲尔德\n",
      "小鸭\n",
      "颤振\n",
      "踩\n",
      "骗子\n",
      "尖叫\n",
      "升起\n",
      "捣碎\n",
      "抑制\n"
     ]
    }
   ],
   "source": [
    "csvFile = open( filename + \".csv\", \"r\",encoding = 'utf-8')\n",
    "reader = csv.reader(csvFile)\n",
    "\n",
    "# API id and key\n",
    "app_id = '491e882b'\n",
    "app_key = 'a0b004ca6b5f7f4e820832f3dc934355'\n",
    "\n",
    "word_pron_char_cate=[]\n",
    "for i in reader:\n",
    "    try:\n",
    "        category = re.findall(\"[a-z]+\\-?[a-z]+\", df.loc[df['word']== i[0] ,'tag'].to_string())\n",
    "        if i[0] in GMAT_list:\n",
    "            category.append('gmat')\n",
    "        cate = \",\".join(category)\n",
    "    \n",
    "        try:\n",
    "    \n",
    "            word_id = i[0]\n",
    "            strictMatch = 'false'\n",
    "\n",
    "            url = 'https://od-api.oxforddictionaries.com:443/api/v2/entries/en-gb/' + word_id.lower() + '?strictMatch=' + strictMatch;\n",
    "\n",
    "            r = requests.get(url, headers = {'app_id': app_id, 'app_key': app_key})\n",
    "            pron = r.json()[\"results\"][0]['lexicalEntries'][0]['entries'][0]['pronunciations'][0]['phoneticSpelling']\n",
    "            char = r.json()[\"results\"][0]['lexicalEntries'][0]['lexicalCategory']['text']\n",
    "            word_pron_char_cate.append([i[0],'/'+pron+'/',char,cate])\n",
    "            print(word_id)\n",
    "            time.sleep(10)\n",
    "        except KeyError :\n",
    "            pass\n",
    "        continue\n",
    "    except IndexError:\n",
    "        pass\n",
    "print('ready for chinese translation')\n",
    "\n",
    "for i in word_pron_char_cate:\n",
    "    if i[2] == 'Noun':\n",
    "        i[2] = 'n.'\n",
    "    if i[2] == 'Adjective':\n",
    "        i[2] = 'adj.'\n",
    "    if i[2] == 'Verb':\n",
    "        i[2] = 'v.'\n",
    "    if i[2] == 'Adverb':\n",
    "        i[2] = 'adv.'\n",
    "\n",
    "# Baidu API for EN-CN Translate\n",
    "appid = '20200627000507736'  # 填写你的appid\n",
    "secretKey = 'G3ghonyD9dfI39NnFtGN'  # 填写你的密钥\n",
    "\n",
    "httpClient = None\n",
    "myurl = '/api/trans/vip/translate'\n",
    "\n",
    "fromLang = 'en'   #原文语种\n",
    "toLang = 'zh'   #译文语种\n",
    "\n",
    "word_pron_char_cate_cn = []\n",
    "for i in word_pron_char_cate:\n",
    "    salt = random.randint(32768, 65536)\n",
    "    sign = appid + i[0] + str(salt) + secretKey\n",
    "    sign = hashlib.md5(sign.encode()).hexdigest()\n",
    "    myurl = myurl + '?appid=' + appid + '&q=' + urllib.parse.quote(i[0]) + '&from=' + fromLang + '&to=' + toLang + '&salt=' + str(salt) + '&sign=' + sign\n",
    "\n",
    "    try:\n",
    "        httpClient = http.client.HTTPConnection('api.fanyi.baidu.com')\n",
    "        httpClient.request('GET', myurl)\n",
    "\n",
    "        # response是HTTPResponse对象\n",
    "        response = httpClient.getresponse()\n",
    "        result_all = response.read().decode(\"utf-8\")\n",
    "        result = json.loads(result_all)['trans_result'][0]['dst']\n",
    "        i.append(result)\n",
    "        print(result)\n",
    "        word_pron_char_cate_cn.append(i)\n",
    "\n",
    "    \n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "fileObject = open(filename + '_v3.txt', 'w',encoding='utf-8')\n",
    "for i in word_pron_char_cate_cn:\n",
    "    for j in i:\n",
    "        fileObject.write(j)\n",
    "        fileObject.write(' ')\n",
    "    fileObject.write('\\n')\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
